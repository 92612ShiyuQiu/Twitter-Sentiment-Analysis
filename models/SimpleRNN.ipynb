{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        # fill in the declarations of the layers here\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # fill the forward logic here\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_and_test_simple_net(input_size, hidden_size, num_classes):\n",
    "    num_epochs = 5\n",
    "    learning_rate = 0.001\n",
    "    model = SimpleNeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Move tensors to the configured device\n",
    "            #images = images.reshape(-1, 28*28).to(device)#\n",
    "            images = images.view(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            # The forward process computes the loss of each iteration on each sample\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and using the optimizer to update the parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Below, an epoch corresponds to one pass through all of the samples.\n",
    "            # Each training step corresponds to a parameter update using \n",
    "            # a gradient computed on a minibatch of 100 samples \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "    # Test the model\n",
    "    # In the test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.reshape(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:08, 1132809.95it/s]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ../../data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:01, 17920.05it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ../../data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 1350940.68it/s]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../../data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 46455.75it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../../data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n",
      "Epoch [1/5], Step [100/600], Loss: 1.7160\n",
      "Epoch [1/5], Step [200/600], Loss: 1.6128\n",
      "Epoch [1/5], Step [300/600], Loss: 1.6083\n",
      "Epoch [1/5], Step [400/600], Loss: 1.5227\n",
      "Epoch [1/5], Step [500/600], Loss: 1.5497\n",
      "Epoch [1/5], Step [600/600], Loss: 1.5273\n",
      "Epoch [2/5], Step [100/600], Loss: 1.5569\n",
      "Epoch [2/5], Step [200/600], Loss: 1.5187\n",
      "Epoch [2/5], Step [300/600], Loss: 1.5136\n",
      "Epoch [2/5], Step [400/600], Loss: 1.5735\n",
      "Epoch [2/5], Step [500/600], Loss: 1.5239\n",
      "Epoch [2/5], Step [600/600], Loss: 1.5438\n",
      "Epoch [3/5], Step [100/600], Loss: 1.5150\n",
      "Epoch [3/5], Step [200/600], Loss: 1.4965\n",
      "Epoch [3/5], Step [300/600], Loss: 1.5182\n",
      "Epoch [3/5], Step [400/600], Loss: 1.4889\n",
      "Epoch [3/5], Step [500/600], Loss: 1.5222\n",
      "Epoch [3/5], Step [600/600], Loss: 1.4765\n",
      "Epoch [4/5], Step [100/600], Loss: 1.4867\n",
      "Epoch [4/5], Step [200/600], Loss: 1.5352\n",
      "Epoch [4/5], Step [300/600], Loss: 1.5124\n",
      "Epoch [4/5], Step [400/600], Loss: 1.4736\n",
      "Epoch [4/5], Step [500/600], Loss: 1.4743\n",
      "Epoch [4/5], Step [600/600], Loss: 1.4862\n",
      "Epoch [5/5], Step [100/600], Loss: 1.4701\n",
      "Epoch [5/5], Step [200/600], Loss: 1.4967\n",
      "Epoch [5/5], Step [300/600], Loss: 1.5330\n",
      "Epoch [5/5], Step [400/600], Loss: 1.5182\n",
      "Epoch [5/5], Step [500/600], Loss: 1.4987\n",
      "Epoch [5/5], Step [600/600], Loss: 1.4902\n",
      "Accuracy of the network on the 10000 test images: 96.28 %\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# The MNIST dataset is a built-in dataset in torchvision\n",
    "batch_size = 100\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "train_and_test_simple_net(28 * 28, 200, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
