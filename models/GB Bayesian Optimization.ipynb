{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "X = np.genfromtxt('../data/X.csv', delimiter=',')\n",
    "Y = np.genfromtxt('../data/Y.csv', delimiter=',')\n",
    "\n",
    "X_comp, X_test, Y_comp, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "Xtr, Xva, Ytr, Yva = train_test_split(X_comp, Y_comp, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st: Tuning \"n_estimators\" and \"learning_rate\"\n",
    "\n",
    "search_space1 = [Integer(1000, 2000, name='n_estimators'), Real(0.001, 1, name=\"learning_rate\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.678\n",
      "Best Parameters: n_estimators=2000\t learning_rate=0.164266\n"
     ]
    }
   ],
   "source": [
    "clf1 = GradientBoostingClassifier(max_depth=3,loss=\"deviance\",min_samples_split=20,\n",
    "                                  min_samples_leaf=9,max_features=\"sqrt\",subsample=0.5)\n",
    "\n",
    "@use_named_args(search_space1)\n",
    "def evaluate_model1(**params):\n",
    "    # something\n",
    "    clf1.set_params(**params)\n",
    "    # calculate 5-fold cross validation\n",
    "    result = cross_val_score(clf1, Xtr[:5000], Ytr[:5000], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    # calculate the mean of the scores\n",
    "    estimate = mean(result)\n",
    "    return 1.0 - estimate\n",
    "\n",
    "result1 = gp_minimize(evaluate_model1, search_space1)\n",
    "print('Best Accuracy: %.3f' % (1.0 - result1.fun))\n",
    "print('Best Parameters: n_estimators=%d\\t learning_rate=%f' % (result1.x[0], result1.x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.677\n",
      "Best Parameters: n_estimators=1000\t learning_rate=0.169135\n"
     ]
    }
   ],
   "source": [
    "clf1 = GradientBoostingClassifier(loss=\"deviance\",max_features=\"sqrt\")\n",
    "\n",
    "@use_named_args(search_space1)\n",
    "def evaluate_model1(**params):\n",
    "    # something\n",
    "    clf1.set_params(**params)\n",
    "    # calculate 5-fold cross validation\n",
    "    result = cross_val_score(clf1, Xtr[:5000], Ytr[:5000], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    # calculate the mean of the scores\n",
    "    estimate = mean(result)\n",
    "    return 1.0 - estimate\n",
    "\n",
    "result1 = gp_minimize(evaluate_model1, search_space1)\n",
    "print('Best Accuracy: %.3f' % (1.0 - result1.fun))\n",
    "print('Best Parameters: n_estimators=%d\\t learning_rate=%f' % (result1.x[0], result1.x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.665\n",
      "Best Parameters: subsample=0.238755\n"
     ]
    }
   ],
   "source": [
    "# 2nd: Tuning \"subsample\"\n",
    "\n",
    "search_space2 = [Real(0, 1, name=\"subsample\")]\n",
    "\n",
    "clf2 = GradientBoostingClassifier(loss=\"deviance\",max_features=\"sqrt\")\n",
    "\n",
    "@use_named_args(search_space2)\n",
    "def evaluate_model2(**params):\n",
    "    # something\n",
    "    clf2.set_params(**params)\n",
    "    # calculate 5-fold cross validation\n",
    "    result = cross_val_score(clf2, Xtr[:5000], Ytr[:5000], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    # calculate the mean of the scores\n",
    "    estimate = mean(result)\n",
    "    return 1.0 - estimate\n",
    "\n",
    "result2 = gp_minimize(evaluate_model2, search_space2)\n",
    "print('Best Accuracy: %.3f' % (1.0 - result2.fun))\n",
    "print('Best Parameters: subsample=%f' % (result2.x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd: Tuning \"max_depth\"\n",
    "\n",
    "search_space3 = [Integer(1, 10, name=\"max_depth\")]\n",
    "\n",
    "clf3 = GradientBoostingClassifier(loss=\"deviance\",max_features=\"sqrt\")\n",
    "\n",
    "@use_named_args(search_space3)\n",
    "def evaluate_model3(**params):\n",
    "    # something\n",
    "    clf3.set_params(**params)\n",
    "    # calculate 5-fold cross validation\n",
    "    result = cross_val_score(clf3, Xtr[:5000], Ytr[:5000], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    # calculate the mean of the scores\n",
    "    estimate = mean(result)\n",
    "    return 1.0 - estimate\n",
    "\n",
    "result3 = gp_minimize(evaluate_model3, search_space3)\n",
    "print('Best Accuracy: %.3f' % (1.0 - result3.fun))\n",
    "print('Best Parameters: max_depth=%d' % (result3.x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.655\n",
      "Best Parameters: min_samples_split=60\t min_samples_leaf=10\n"
     ]
    }
   ],
   "source": [
    "# 4th: Tuning \"min_samples_split\" and \"min_samples_leaf\"\n",
    "\n",
    "search_space4 = [Integer(2, 60, name=\"min_samples_split\"), Integer(1, 10, name=\"min_samples_leaf\")]\n",
    "\n",
    "clf4 = GradientBoostingClassifier(loss=\"deviance\",max_features=\"sqrt\")\n",
    "\n",
    "@use_named_args(search_space4)\n",
    "def evaluate_model4(**params):\n",
    "    # something\n",
    "    clf4.set_params(**params)\n",
    "    # calculate 5-fold cross validation\n",
    "    result = cross_val_score(clf4, Xtr[:5000], Ytr[:5000], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    # calculate the mean of the scores\n",
    "    estimate = mean(result)\n",
    "    return 1.0 - estimate\n",
    "\n",
    "result4 = gp_minimize(evaluate_model4, search_space4)\n",
    "print('Best Accuracy: %.3f' % (1.0 - result4.fun))\n",
    "print('Best Parameters: min_samples_split=%d\\t min_samples_leaf=%d' % (result4.x[0], result4.x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "training finished, took 57.00570225715637 seconds\n",
      "0.7597870794993593\n",
      "training acc: 0.7140937290016095\n",
      "validation acc: 0.6900431276954809\n"
     ]
    }
   ],
   "source": [
    "# final classifier\n",
    "\n",
    "clf = GradientBoostingClassifier(max_depth=4,loss=\"deviance\",learning_rate=0.169135,\n",
    "                                 n_estimators=1000,min_samples_split=60,min_samples_leaf=10,\n",
    "                                 max_features=\"sqrt\", subsample=0.637095)\n",
    "\n",
    "print('training start')\n",
    "starting_time = time.time()\n",
    "clf.fit(Xtr, Ytr)\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "gradient_boosting_classifier_roc = roc_auc_score(\n",
    "   Yva, clf.predict_proba(Xva)[:,1])\n",
    "print(gradient_boosting_classifier_roc)\n",
    "\n",
    "print(\"training acc:\", clf.score(Xtr, Ytr))\n",
    "print(\"validation acc:\", clf.score(Xva, Yva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "training finished, took 36.625677824020386 seconds\n",
      "0.7577584519299772\n",
      "training acc: 0.7036238338568281\n",
      "validation acc: 0.6907931745734108\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=4,loss=\"deviance\",learning_rate=0.169135,\n",
    "                                 n_estimators=1000,min_samples_split=60,min_samples_leaf=10,\n",
    "                                 max_features=\"sqrt\", subsample=0.238755)\n",
    "\n",
    "print('training start')\n",
    "starting_time = time.time()\n",
    "clf.fit(Xtr, Ytr)\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "gradient_boosting_classifier_roc = roc_auc_score(\n",
    "   Yva, clf.predict_proba(Xva)[:,1])\n",
    "print(gradient_boosting_classifier_roc)\n",
    "\n",
    "print(\"training acc:\", clf.score(Xtr, Ytr))\n",
    "print(\"validation acc:\", clf.score(Xva, Yva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "training finished, took 117.7537190914154 seconds\n",
      "0.7573753461649787\n",
      "training acc: 0.7234697545043989\n",
      "validation acc: 0.6912932058253641\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=4,loss=\"deviance\",learning_rate=0.169135,\n",
    "                                 n_estimators=2000,min_samples_split=60,min_samples_leaf=10,\n",
    "                                 max_features=\"sqrt\", subsample=0.637095)\n",
    "\n",
    "print('training start')\n",
    "starting_time = time.time()\n",
    "clf.fit(Xtr, Ytr)\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "gradient_boosting_classifier_roc = roc_auc_score(\n",
    "   Yva, clf.predict_proba(Xva)[:,1])\n",
    "print(gradient_boosting_classifier_roc)\n",
    "\n",
    "print(\"training acc:\", clf.score(Xtr, Ytr))\n",
    "print(\"validation acc:\", clf.score(Xva, Yva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.678\n",
      "Best Parameters: n_estimators=1732\t learning_rate=0.273843 \n",
      "        subsample=0.632756\t max_depth=5 \n",
      "        min_samples_split=22\t min_samples_leaf=8\n"
     ]
    }
   ],
   "source": [
    "search_space = [Integer(1000, 2000, name='n_estimators'), Real(0.001, 1, name=\"learning_rate\"), \n",
    "               Real(0.1, 1, name=\"subsample\"), Integer(1, 10, name=\"max_depth\"), \n",
    "               Integer(2, 60, name=\"min_samples_split\"), Integer(1, 10, name=\"min_samples_leaf\")]\n",
    "\n",
    "clf = GradientBoostingClassifier(loss=\"deviance\",max_features=\"sqrt\")\n",
    "\n",
    "@use_named_args(search_space)\n",
    "def evaluate_model(**params):\n",
    "    # something\n",
    "    clf.set_params(**params)\n",
    "    # calculate 5-fold cross validation\n",
    "    result = cross_val_score(clf, Xtr[:5000], Ytr[:5000], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    # calculate the mean of the scores\n",
    "    estimate = mean(result)\n",
    "    return 1.0 - estimate\n",
    "\n",
    "result = gp_minimize(evaluate_model, search_space)\n",
    "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
    "print('Best Parameters: n_estimators=%d\\t learning_rate=%f \\n\\\n",
    "        subsample=%f\\t max_depth=%d \\n\\\n",
    "        min_samples_split=%d\\t min_samples_leaf=%d' % (result.x[0], result.x[1], result.x[2], \n",
    "                                                       result.x[3], result.x[4], result.x[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "training finished, took 115.02713084220886 seconds\n",
      "0.7461494089838409\n",
      "training acc: 0.741346709796384\n",
      "validation acc: 0.6814175885992875\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=5,loss=\"deviance\",learning_rate=0.273843,\n",
    "                                 n_estimators=1732,min_samples_split=22,min_samples_leaf=8,\n",
    "                                 max_features=\"sqrt\", subsample=0.632756)\n",
    "\n",
    "print('training start')\n",
    "starting_time = time.time()\n",
    "clf.fit(Xtr, Ytr)\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "gradient_boosting_classifier_roc = roc_auc_score(\n",
    "   Yva, clf.predict_proba(Xva)[:,1])\n",
    "print(gradient_boosting_classifier_roc)\n",
    "\n",
    "print(\"training acc:\", clf.score(Xtr, Ytr))\n",
    "print(\"validation acc:\", clf.score(Xva, Yva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "training finished, took 61.780189990997314 seconds\n",
      "0.7596461415512974\n",
      "training acc: 0.7050614911005891\n",
      "validation acc: 0.6902931433214576\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=3,loss=\"deviance\",learning_rate=0.1,\n",
    "                                 n_estimators=1500,min_samples_split=20,min_samples_leaf=9,\n",
    "                                 max_features=\"sqrt\", subsample=0.5)\n",
    "\n",
    "print('training start')\n",
    "starting_time = time.time()\n",
    "clf.fit(Xtr, Ytr)\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "gradient_boosting_classifier_roc = roc_auc_score(\n",
    "   Yva, clf.predict_proba(Xva)[:,1])\n",
    "print(gradient_boosting_classifier_roc)\n",
    "\n",
    "print(\"training acc:\", clf.score(Xtr, Ytr))\n",
    "print(\"validation acc:\", clf.score(Xva, Yva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [Real(0, 1, name=\"subsample\")]\n",
    "\n",
    "clf6 = GradientBoostingClassifier(max_depth=3,loss=\"deviance\",learning_rate=0.1,\n",
    "                                 n_estimators=1500,min_samples_split=20,min_samples_leaf=9,\n",
    "                                 max_features=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(search_space)\n",
    "def evaluate_model(**params):\n",
    "    # something\n",
    "    clf6.set_params(**params)\n",
    "    # calculate 5-fold cross validation\n",
    "    result = cross_val_score(clf6, Xtr[:5000], Ytr[:5000], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    # calculate the mean of the scores\n",
    "    estimate = mean(result)\n",
    "    return 1.0 - estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.678\n",
      "Best Parameters: subsample=0.637095\n"
     ]
    }
   ],
   "source": [
    "result = gp_minimize(evaluate_model, search_space)\n",
    "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
    "print('Best Parameters: subsample=%f' % (result.x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "training finished, took 68.53286004066467 seconds\n",
      "0.7616694713965693\n",
      "training acc: 0.7048427171721907\n",
      "validation acc: 0.6950434402150134\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=3,loss=\"deviance\",learning_rate=0.1,\n",
    "                                 n_estimators=1500,min_samples_split=20,min_samples_leaf=9,\n",
    "                                 max_features=\"sqrt\", subsample=0.637095)\n",
    "print('training start')\n",
    "starting_time = time.time()\n",
    "clf.fit(Xtr, Ytr)\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "gradient_boosting_classifier_roc = roc_auc_score(\n",
    "   Yva, clf.predict_proba(Xva)[:,1])\n",
    "print(gradient_boosting_classifier_roc)\n",
    "\n",
    "print(\"training acc:\", clf.score(Xtr, Ytr))\n",
    "print(\"validation acc:\", clf.score(Xva, Yva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7602428367100331\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_classifier_roc = roc_auc_score(\n",
    "   Y_test, clf.predict_proba(X_test)[:,1])\n",
    "print(gradient_boosting_classifier_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "search_space2 = [Integer(1000, 2000, name='n_estimators'), Real(0.001, 1, name=\"learning_rate\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.687\n",
      "Best Parameters: n_estimators=1000\t learning_rate=0.160222\n"
     ]
    }
   ],
   "source": [
    "clf1 = GradientBoostingClassifier(max_depth=3,loss=\"deviance\",min_samples_split=20,\n",
    "                                  min_samples_leaf=9,max_features=\"sqrt\",subsample=0.637095)\n",
    "\n",
    "@use_named_args(search_space2)\n",
    "def evaluate_model2(**params):\n",
    "    # something\n",
    "    clf1.set_params(**params)\n",
    "    # calculate 5-fold cross validation\n",
    "    result = cross_val_score(clf1, Xtr[:10000], Ytr[:10000], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    # calculate the mean of the scores\n",
    "    estimate = mean(result)\n",
    "    return 1.0 - estimate\n",
    "\n",
    "result2 = gp_minimize(evaluate_model2, search_space2)\n",
    "print('Best Accuracy: %.3f' % (1.0 - result2.fun))\n",
    "print('Best Parameters: n_estimators=%d\\t learning_rate=%f' % (result2.x[0], result2.x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.685\n",
      "Best Parameters: n_estimators=1000\t learning_rate=0.081586\n"
     ]
    }
   ],
   "source": [
    "clf1 = GradientBoostingClassifier(max_depth=3,loss=\"deviance\",min_samples_split=20,\n",
    "                                  min_samples_leaf=9,max_features=\"sqrt\",subsample=0.637095)\n",
    "\n",
    "@use_named_args(search_space2)\n",
    "def evaluate_model2(**params):\n",
    "    # something\n",
    "    clf1.set_params(**params)\n",
    "    # calculate 5-fold cross validation\n",
    "    result = cross_val_score(clf1, Xtr[:5000], Ytr[:5000], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    # calculate the mean of the scores\n",
    "    estimate = mean(result)\n",
    "    return 1.0 - estimate\n",
    "\n",
    "result2 = gp_minimize(evaluate_model2, search_space2)\n",
    "print('Best Accuracy: %.3f' % (1.0 - result2.fun))\n",
    "print('Best Parameters: n_estimators=%d\\t learning_rate=%f' % (result2.x[0], result2.x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
