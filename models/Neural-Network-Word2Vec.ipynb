{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import scipy.sparse\n",
    "\n",
    "X = np.genfromtxt('X_word2vec.csv', delimiter = ',')\n",
    "Y = np.genfromtxt('../new_data/Y.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "X = X[1:,]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y[1:]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comp, X_test, Y_comp, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "Xtr, Xva, Ytr, Yva = train_test_split(X_comp, Y_comp, test_size=0.2)\n",
    "Xtr, Ytr = shuffle(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64000, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xva.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp = MLPClassifier(max_iter=1000)\n",
    "parameters1 = {\n",
    "    'hidden_layer_sizes': [(100,100,100),(100,150,50),(150,100,50),(200,100),(200,50,50),(150,150),(300,)]\n",
    "}\n",
    "\n",
    "parameters2 = {\n",
    "    'activation': ['relu','identity','logistic','tanh']\n",
    "}\n",
    "\n",
    "parameters3 = {\n",
    "    'solver': ['adam','lbfgs','sgd']\n",
    "}\n",
    "\n",
    "parameters4 = {\n",
    "    'alpha': [0.0001, 0.05, 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "parameters5 = {\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters1 training starting...\n",
      "training finished, took 489.6069812774658 seconds\n",
      "Best parameters found: \n",
      " {'hidden_layer_sizes': (300,)}\n",
      "0.686 (+/-0.031) for {'hidden_layer_sizes': (100, 100, 100)}\n",
      "0.694 (+/-0.021) for {'hidden_layer_sizes': (100, 150, 50)}\n",
      "0.689 (+/-0.030) for {'hidden_layer_sizes': (150, 100, 50)}\n",
      "0.699 (+/-0.028) for {'hidden_layer_sizes': (200, 100)}\n",
      "0.693 (+/-0.018) for {'hidden_layer_sizes': (200, 50, 50)}\n",
      "0.689 (+/-0.023) for {'hidden_layer_sizes': (150, 150)}\n",
      "0.705 (+/-0.026) for {'hidden_layer_sizes': (300,)}\n"
     ]
    }
   ],
   "source": [
    "print(\"parameters1 training starting...\")\n",
    "starting_time = time.time()\n",
    "clf1 = GridSearchCV(MLPClassifier(max_iter=1000), parameters1, cv=5)\n",
    "clf1.fit(Xtr[:5000], Ytr[:5000])\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "#best parameter set\n",
    "print(\"Best parameters found: \\n\", clf1.best_params_)\n",
    "\n",
    "#all results\n",
    "means = clf1.cv_results_['mean_test_score']\n",
    "stds = clf1.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf1.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hidden_layer_sizes:  (300,)\n"
     ]
    }
   ],
   "source": [
    "best_hidden_layer_sizes = clf1.best_params_['hidden_layer_sizes']\n",
    "print(\"best hidden_layer_sizes: \", best_hidden_layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters2 training starting...\n",
      "training finished, took 221.63074326515198 seconds\n",
      "Best parameters found: \n",
      " {'activation': 'identity'}\n",
      "0.701 (+/-0.024) for {'activation': 'relu'}\n",
      "0.743 (+/-0.037) for {'activation': 'identity'}\n",
      "0.741 (+/-0.030) for {'activation': 'logistic'}\n",
      "0.743 (+/-0.024) for {'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print(\"parameters2 training starting...\")\n",
    "starting_time = time.time()\n",
    "clf2 = GridSearchCV(MLPClassifier(max_iter=1000, hidden_layer_sizes=best_hidden_layer_sizes), parameters2, cv=5)\n",
    "clf2.fit(Xtr[:5000], Ytr[:5000])\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "#best parameter set\n",
    "print(\"Best parameters found: \\n\", clf2.best_params_)\n",
    "\n",
    "#all results\n",
    "means = clf2.cv_results_['mean_test_score']\n",
    "stds = clf2.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf2.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_activation:  identity\n"
     ]
    }
   ],
   "source": [
    "best_activation = clf2.best_params_['activation']\n",
    "print(\"best_activation: \", best_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters3 training starting...\n",
      "training finished, took 82.52945876121521 seconds\n",
      "Best parameters found: \n",
      " {'solver': 'adam'}\n",
      "0.745 (+/-0.030) for {'solver': 'adam'}\n",
      "0.745 (+/-0.032) for {'solver': 'lbfgs'}\n",
      "0.745 (+/-0.033) for {'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "print(\"parameters3 training starting...\")\n",
    "starting_time = time.time()\n",
    "clf3 = GridSearchCV(MLPClassifier(max_iter=1000, hidden_layer_sizes=best_hidden_layer_sizes, activation=best_activation), parameters3, cv=5)\n",
    "clf3.fit(Xtr[:5000], Ytr[:5000])\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "#best parameter set\n",
    "print(\"Best parameters found: \\n\", clf3.best_params_)\n",
    "\n",
    "#all results\n",
    "means = clf3.cv_results_['mean_test_score']\n",
    "stds = clf3.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf3.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_solver:  adam\n"
     ]
    }
   ],
   "source": [
    "best_solver = clf3.best_params_['solver']\n",
    "print(\"best_solver: \", best_solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters4 training starting...\n",
      "training finished, took 75.49126839637756 seconds\n",
      "Best parameters found: \n",
      " {'alpha': 0.05}\n",
      "0.743 (+/-0.028) for {'alpha': 0.0001}\n",
      "0.745 (+/-0.033) for {'alpha': 0.05}\n",
      "0.744 (+/-0.030) for {'alpha': 0.1}\n",
      "0.741 (+/-0.040) for {'alpha': 0.01}\n",
      "0.739 (+/-0.033) for {'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(\"parameters4 training starting...\")\n",
    "starting_time = time.time()\n",
    "clf4 = GridSearchCV(MLPClassifier(max_iter=1000, hidden_layer_sizes=best_hidden_layer_sizes, activation=best_activation, solver=best_solver), parameters4, cv=5)\n",
    "clf4.fit(Xtr[:5000], Ytr[:5000])\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "#best parameter set\n",
    "print(\"Best parameters found: \\n\", clf4.best_params_)\n",
    "\n",
    "#all results\n",
    "means = clf4.cv_results_['mean_test_score']\n",
    "stds = clf4.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf4.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_alpha:  0.05\n"
     ]
    }
   ],
   "source": [
    "best_alpha = clf4.best_params_['alpha']\n",
    "print(\"best_alpha: \", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters5 training starting...\n",
      "training finished, took 76.17743277549744 seconds\n",
      "Best parameters found: \n",
      " {'learning_rate': 'invscaling'}\n",
      "0.740 (+/-0.028) for {'learning_rate': 'constant'}\n",
      "0.744 (+/-0.033) for {'learning_rate': 'invscaling'}\n",
      "0.744 (+/-0.033) for {'learning_rate': 'adaptive'}\n"
     ]
    }
   ],
   "source": [
    "print(\"parameters5 training starting...\")\n",
    "starting_time = time.time()\n",
    "clf5 = GridSearchCV(MLPClassifier(max_iter=1000, hidden_layer_sizes=best_hidden_layer_sizes, activation=best_activation, solver=best_solver, alpha=best_alpha), parameters5, cv=5)\n",
    "clf5.fit(Xtr[:5000], Ytr[:5000])\n",
    "end_time = time.time()\n",
    "print(\"training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "#best parameter set\n",
    "print(\"Best parameters found: \\n\", clf5.best_params_)\n",
    "\n",
    "#all results\n",
    "means = clf5.cv_results_['mean_test_score']\n",
    "stds = clf5.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf5.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_learning_rate:  invscaling\n"
     ]
    }
   ],
   "source": [
    "best_learning_rate = clf5.best_params_['learning_rate']\n",
    "print(\"best_learning_rate: \", best_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(300,), learning_rate='invscaling',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_mlp = MLPClassifier(max_iter=1000, hidden_layer_sizes=best_hidden_layer_sizes, \n",
    "                            activation=best_activation, solver=best_solver, alpha=best_alpha, \n",
    "                            learning_rate=best_learning_rate)\n",
    "optimal_mlp.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_mlp_roc:  0.8346029536352948\n",
      "training error: 0.24953124999999998\n",
      "validation error: 0.24706249999999996\n"
     ]
    }
   ],
   "source": [
    "optimal_mlp_roc = roc_auc_score(Yva, optimal_mlp.predict_proba(Xva)[:,1])\n",
    "print(\"optimal_mlp_roc: \", optimal_mlp_roc)\n",
    "print(\"training error:\", 1 - optimal_mlp.score(Xtr, Ytr))\n",
    "print(\"validation error:\", 1 - optimal_mlp.score(Xva, Yva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_mlp_roc = roc_auc_score(Yva, optimal_mlp.predict_proba(Xva)[:,1])\n",
    "print(\"optimal_mlp_roc: \", optimal_mlp_roc)\n",
    "print(\"training error:\", 1 - optimal_mlp.score(Xtr, Ytr))\n",
    "print(\"validation error:\", 1 - optimal_mlp.score(Xva, Yva))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
